---
title: "Bayes_Rules!_Notebook"
format: html
editor: visual
---

## Chapter 2: Bayes' Rule

```{r}
library(bayesrules)
library(tidyverse)

set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
data(fake_news)
fake_news <- fake_news |> as_tibble()

fake_news |> 
  count(type)
```

```{r}
fake_news |> 
  summarize(n = n(), .by = c(title_has_excl, type))
```

```{r}
sim_params <- tibble(type = c("real", "fake"),
                     prior = c(0.6, 0.4))

set.seed(1234)

sims <- sample(sim_params$type, size = 10000, prob = sim_params$prior, replace = TRUE) |>
  enframe(value = "type") |> 
  mutate(data_model = case_when(
    type == "fake" ~ .2667,
    type == "real" ~ .0222
  )) |> 
  rowwise() |> 
  mutate(usage = sample(
    c("no", "yes"), size = 1, prob = c(1- data_model, data_model)
    )) |> 
  ungroup()

sims |> 
  summarize(n = n(), .by = c(usage, type))
```

```{r}
ggplot(sims) +
  aes(x = type, fill = usage) +
  geom_bar(position = "fill")
```

```{r}
data("pop_vs_soda")

pop_vs_soda |> 
  summarize(n = n(), .by = c(pop, region))
```

```{r}
chess <- c(0.2, .5, .8)
prior <- c(0.1, 0.25, 0.65)

set.seed(1234)
chess_sim <- tibble(
  pi = sample(chess, size = 10000, prob = prior, replace = TRUE) 
)|> 
  mutate(y = rbinom(n(), size = 6, prob = pi))

chess_sim |> 
  count(pi) |> 
  mutate(prop = n / sum(n))
```

```{r}
chess_sim |> 
  ggplot() +
  aes(x = y) +
  stat_count(aes(y = after_stat(prop))) +
  facet_wrap(~pi)
```

## Chapter 3: The Beta-Binomial Bayesian Model

```{r}
library(bayesrules)
library(tidyverse)
library(extraDistr)
library(brms)
library(tidybayes)
```

```{r}
ggplot() +
  geom_function(fun = ~dbeta(., 45, 55), n = 10000) +
  labs(title = "dbeta(45, 55)")
```

```{r}
model_election <- brm(
  bf(support | trials(n_in_poll) ~ 0 + Intercept),
  data = list(support = 30, n_in_poll = 50),
  family = binomial(link = "identity"),
  prior(beta(45, 55), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234, backend = "rstan",
  cores = 8
)
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
  stat_halfeye(fill = "firebrick3") +
  labs(x = "pi", title = "Posterior for Michelle's support")
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
   stat_function(geom = "area", 
                fun = ~dbeta(., 45, 55), aes(fill = "Prior"), alpha = .75) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = 0.75) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  labs(x = "pi", title = "Posterior (Red) + Prior (Gray) for Michelle's support")
```

```{r}
model_milgram <- brm(
  bf(obey | trials(participants) ~ 0 + Intercept),
  data = list(obey = 26, participants = 40),
  family = binomial(link = "identity"),
  prior(beta(1, 10), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234,
  backend = "rstan", cores = 8
)
```

```{r}
model_milgram |> 
  gather_draws(b_Intercept) |> 
  ggplot() +
  aes(x = .value) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = .75) +
  stat_function(aes(fill = "Prior"), fun = ~dbeta(., 1, 10), 
                alpha = .75, geom = "area") +
  xlim(0, 1) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  ggtitle("Listening to Authority: Prior (Gray) vs Posterior (Red)")
```

## Chapter 6: Approximating the Posterior

```{r}
library(bayesrules)
library(tidyverse)
library(cmdstanr)
library(posterior)
library(tidybayes)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 6)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

grid_data
```

```{r}
ggplot(grid_data) +
  aes(x = pi_grid, y = posterior) +
  geom_point() +
  geom_segment(aes(xend = pi_grid, yend = 0))
```

```{r}
posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

posterior_samples|> 
  count(pi_grid)
```

```{r}
ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.1, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 10000)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.01, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
bb_sim <- cmdstan_model("06_stan/bb_sim.stan")
```

```{r}
bb_sim_samples <- bb_sim$sample(
  data = list(Y = 9), 
  parallel_chains = 4,
  iter_warmup = 2500,
  iter_sampling = 2500,
  refresh = 0,
  seed = 1234
)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  head(4)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() + 
  aes(x = pi) +
  stat_density(geom = "area", fill = "firebrick3") +
  stat_function(fun = ~dbeta(., 11, 3), color = "grey6", linewidth = 2)
```

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +
  geom_line(size = 0.1) +
  labs(color = "Chain")
```

Looks random!

```{r}
bb_sim_samples |>
  spread_draws(pi) |> 
  mutate(draw_rank = rank(pi)) |> 
  ggplot(aes(x = draw_rank)) +
  stat_bin(aes(color = factor(.chain)), geom = "step", binwidth = 500, 
           position = position_identity(), boundary = 0) + 
  labs(color = "Chain") +
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())
```

According to McElreath (p. 284),

> If the chains are exploring the same space efficiently, the histograms should be similar to one another and largely overlapping.

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi, color = factor(.chain)) +
  geom_density() +
  labs(color = "Chain")
```

Looks consistent across the four chains!

```{r}
brms::neff_ratio(bb_sim_samples)
```

“Our 20,000 Markov chain values are about as useful as only 6800 independent samples (0.34 × 20000).” Happy that this number is greater than .1

```{r}
bayesplot::mcmc_acf(bb_sim_samples$draws(variables = "pi"))
```

Dies off pretty quick!

```{r}
rhat_basic(bb_sim_samples$draws(variables = "pi"))
```

Not greater than 1.01 so good!

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value)) +
  geom_line(size = 0.1) 
```

Looks random enough.

## Chapter 7: Markov Chain Monte Carlo under the hood

```{r}
library(tidyverse)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

"Think of Markov chains as a tour around the range of posterior possible values of a parameter (like µ or π or whatever). The chains move around that parameter and hopefully converge around it, but the chains need a tour manager to do that properly."

```{r}
one_mh_iteration <- function(w, current){
  proposal <- runif(1, min = current-w, max = current + w)
  proposal_plausibility <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
  current_plausibility <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
  
  alpha <- min(1, proposal_plausibility / current_plausibility)
  next_stop <- sample(c(proposal, current), size = 1, prob = c(alpha, 1 - alpha))
  
  return(tibble(proposal, alpha, next_stop))
}

set.seed(8)
one_mh_iteration(w = 1, current = 3)
```

```{r}
mh_tour <- function(start = 3, N, w){
  current <- start
  mu <- rep(0, N)
  
  for(i in 1:N){
    where_next <- one_mh_iteration(w = w, current = current)
    
    mu[i] <- where_next$next_stop
    
    current <- where_next$next_stop
  }
  
  return(tibble(.iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
tour_1 <- mh_tour(start = 3, N = 5000, w = 1)

tour_1 |> 
  ggplot(aes(x = .iteration, y = mu)) +
  geom_line(size = 0.1, alpha = 0.75)
```

```{r}
tour_1 |> 
  ggplot(aes(x = mu)) +
  geom_histogram(aes(y = after_stat(density)),binwidth = 0.25, 
                  color = "white", fill = "firebrick3") +
  geom_function(fun = ~dnorm(., 4, 0.6), color = "grey12")
```

## Chapter 8: Posterior Inference and Prediction

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(tidybayes)
library(ggdist)

set_theme(theme_bw(base_family = "Barlow", base_size = 16))
```

Our prior looks like

```{r}
ggplot() +
  stat_function(fun = ~dbeta(., 4, 6), geom = "area", fill = "#f6b97b")
```

```{r}
data("moma_sample")
glimpse(moma_sample, width = 80)
```

```{r}
moma_sample |> 
  count(genx)
```

```{r}
ggplot() +
  stat_function(aes(fill = "Prior: Beta (4, 6)"), 
                fun = ~dbeta(., 4, 6), geom = "area") +
  stat_function(aes(fill = "Posterior: Beta (18, 92)"), 
                fun = ~dbeta(., 18, 92), geom = "area") +
  scale_fill_manual(values = c("#940034", "#f6b97b")) +
  theme(legend.position = "inside", legend.position.inside =  c(.8, .8))
```

```{r}
# BRMS version of approx

model_pi_brms <- brm(
  bf(num_genx | trials(artworks) ~ 0 + Intercept),
  data = list(num_genx = 14, artworks = 100),
  family = binomial(link = "identity"),
  prior(beta(4, 6), class = b, lb = 0, ub = 1),
  sample_prior = TRUE,
  iter = 5000, 
  warmup = 1000,
  seed = 1234, 
  backend = "cmdstanr", cores = 8, refresh = 0
)
```

```{r}
# stan version of approx

model_pi_stan <- cmdstan_model("08_stan/genx.stan")
```

```{r}
pi_stan_samples <- model_pi_stan$sample(
  data = list(artworks = 100, num_genx = 14),
  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500,
  refresh = 0, seed = 1234
)
```

95% credible interval:

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

95% credible interval with highest posterior densities:

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  median_hdci(pi, width = .95)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.5, 0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  labs(fill_ramp = "Credible Interval") +
  theme(legend.position = "inside", legend.position.inside = c(.83, .8))
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  count(pi < .2) |> 
  mutate(prob = n/sum(n))
```

84.73% chance that pi is less than 0.2

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot(aes(x = pi)) +
  stat_halfeye(aes(fill_ramp = after_stat(x < 0.2)), fill = "#2db25f") +
  scale_fill_ramp_discrete(from = "#8ee7af", guide = "none") +
  geom_vline(xintercept = .2, linewidth = .5, color = "grey35")
```

Region of Practical Equivalence (ROPE)

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  summarize(prop_in_rope = sum(pi > 0.25 & pi < 0.35) / n(),
            prop_outside_rope = 1 - prop_in_rope)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  annotate(geom = "rect", xmin = 0.25, xmax = 0.35, 
           ymin = -Inf, ymax = Inf, alpha = 0.3)+   geom_vline(xintercept = 0.3) +
  xlim(c(0, 0.4)) +
  theme(legend.position = "none")
```

Posterior prediction

```{r}
# brms way

predicted_genx_after_20 <- model_pi_brms |> 
  predicted_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  summarize(n = n(), .by = .prediction) |> 
  mutate(prop = n / sum(n)) |> arrange(.prediction)

predicted_genx_after_20
```

```{r}
ggplot(predicted_genx_after_20) +
  aes(x = factor(.prediction), y = prop) +
  geom_col()
```

```{r}
predicted_genx_after_20 |> 
  filter(.prediction == 3) |> 
  pull(prop)
```

Distribution of above

```{r}
model_pi_brms |> 
  epred_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  ggplot() + 
  aes(x = .epred) +
  stat_halfeye()
```
