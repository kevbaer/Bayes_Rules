---
title: "Bayes_Rules!_Notebook"
format: html
editor: visual
---

## Chapter 2: Bayes' Rule

```{r}
library(bayesrules)
library(tidyverse)

set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
data(fake_news)
fake_news <- fake_news |> as_tibble()

fake_news |> 
  count(type)
```

```{r}
fake_news |> 
  summarize(n = n(), .by = c(title_has_excl, type))
```

```{r}
sim_params <- tibble(type = c("real", "fake"),
                     prior = c(0.6, 0.4))

set.seed(1234)

sims <- sample(sim_params$type, size = 10000, prob = sim_params$prior, replace = TRUE) |>
  enframe(value = "type") |> 
  mutate(data_model = case_when(
    type == "fake" ~ .2667,
    type == "real" ~ .0222
  )) |> 
  rowwise() |> 
  mutate(usage = sample(
    c("no", "yes"), size = 1, prob = c(1- data_model, data_model)
    )) |> 
  ungroup()

sims |> 
  summarize(n = n(), .by = c(usage, type))
```

```{r}
ggplot(sims) +
  aes(x = type, fill = usage) +
  geom_bar(position = "fill")
```

```{r}
data("pop_vs_soda")

pop_vs_soda |> 
  summarize(n = n(), .by = c(pop, region))
```

```{r}
chess <- c(0.2, .5, .8)
prior <- c(0.1, 0.25, 0.65)

set.seed(1234)
chess_sim <- tibble(
  pi = sample(chess, size = 10000, prob = prior, replace = TRUE) 
)|> 
  mutate(y = rbinom(n(), size = 6, prob = pi))

chess_sim |> 
  count(pi) |> 
  mutate(prop = n / sum(n))
```

```{r}
chess_sim |> 
  ggplot() +
  aes(x = y) +
  stat_count(aes(y = after_stat(prop))) +
  facet_wrap(~pi)
```

## Chapter 3: The Beta-Binomial Bayesian Model

```{r}
library(bayesrules)
library(tidyverse)
library(extraDistr)
library(brms)
library(tidybayes)
```

```{r}
ggplot() +
  geom_function(fun = ~dbeta(., 45, 55), n = 10000) +
  labs(title = "dbeta(45, 55)")
```

```{r}
model_election <- brm(
  bf(support | trials(n_in_poll) ~ 0 + Intercept),
  data = list(support = 30, n_in_poll = 50),
  family = binomial(link = "identity"),
  prior(beta(45, 55), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234, backend = "rstan",
  cores = 8
)
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
  stat_halfeye(fill = "firebrick3") +
  labs(x = "pi", title = "Posterior for Michelle's support")
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
   stat_function(geom = "area", 
                fun = ~dbeta(., 45, 55), aes(fill = "Prior"), alpha = .75) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = 0.75) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  labs(x = "pi", title = "Posterior (Red) + Prior (Gray) for Michelle's support")
```

```{r}
model_milgram <- brm(
  bf(obey | trials(participants) ~ 0 + Intercept),
  data = list(obey = 26, participants = 40),
  family = binomial(link = "identity"),
  prior(beta(1, 10), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234,
  backend = "rstan", cores = 8
)
```

```{r}
model_milgram |> 
  gather_draws(b_Intercept) |> 
  ggplot() +
  aes(x = .value) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = .75) +
  stat_function(aes(fill = "Prior"), fun = ~dbeta(., 1, 10), 
                alpha = .75, geom = "area") +
  xlim(0, 1) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  ggtitle("Listening to Authority: Prior (Gray) vs Posterior (Red)")
```

## Chapter 6: Approximating the Posterior

```{r}
library(bayesrules)
library(tidyverse)
library(cmdstanr)
library(posterior)
library(tidybayes)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 6)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

grid_data
```

```{r}
ggplot(grid_data) +
  aes(x = pi_grid, y = posterior) +
  geom_point() +
  geom_segment(aes(xend = pi_grid, yend = 0))
```

```{r}
posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

posterior_samples|> 
  count(pi_grid)
```

```{r}
ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.1, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 10000)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.01, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
bb_sim <- cmdstan_model("06_stan/bb_sim.stan")
```

```{r}
bb_sim_samples <- bb_sim$sample(
  data = list(Y = 9), 
  parallel_chains = 4,
  iter_warmup = 2500,
  iter_sampling = 2500,
  refresh = 0,
  seed = 1234
)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  head(4)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() + 
  aes(x = pi) +
  stat_density(geom = "area", fill = "firebrick3") +
  stat_function(fun = ~dbeta(., 11, 3), color = "grey6", linewidth = 2)
```

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +
  geom_line(size = 0.1) +
  labs(color = "Chain")
```

Looks random!

```{r}
bb_sim_samples |>
  spread_draws(pi) |> 
  mutate(draw_rank = rank(pi)) |> 
  ggplot(aes(x = draw_rank)) +
  stat_bin(aes(color = factor(.chain)), geom = "step", binwidth = 500, 
           position = position_identity(), boundary = 0) + 
  labs(color = "Chain") +
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())
```

According to McElreath (p. 284),

> If the chains are exploring the same space efficiently, the histograms should be similar to one another and largely overlapping.

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi, color = factor(.chain)) +
  geom_density() +
  labs(color = "Chain")
```

Looks consistent across the four chains!

```{r}
brms::neff_ratio(bb_sim_samples)
```

“Our 20,000 Markov chain values are about as useful as only 6800 independent samples (0.34 × 20000).” Happy that this number is greater than .1

```{r}
bayesplot::mcmc_acf(bb_sim_samples$draws(variables = "pi"))
```

Dies off pretty quick!

```{r}
rhat_basic(bb_sim_samples$draws(variables = "pi"))
```

Not greater than 1.01 so good!

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value)) +
  geom_line(size = 0.1) 
```

Looks random enough.

## Chapter 7: Markov Chain Monte Carlo under the hood

```{r}
library(tidyverse)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

"Think of Markov chains as a tour around the range of posterior possible values of a parameter (like µ or π or whatever). The chains move around that parameter and hopefully converge around it, but the chains need a tour manager to do that properly."

```{r}
one_mh_iteration <- function(w, current){
  proposal <- runif(1, min = current-w, max = current + w)
  proposal_plausibility <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
  current_plausibility <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
  
  alpha <- min(1, proposal_plausibility / current_plausibility)
  next_stop <- sample(c(proposal, current), size = 1, prob = c(alpha, 1 - alpha))
  
  return(tibble(proposal, alpha, next_stop))
}

set.seed(8)
one_mh_iteration(w = 1, current = 3)
```

```{r}
mh_tour <- function(start = 3, N, w){
  current <- start
  mu <- rep(0, N)
  
  for(i in 1:N){
    where_next <- one_mh_iteration(w = w, current = current)
    
    mu[i] <- where_next$next_stop
    
    current <- where_next$next_stop
  }
  
  return(tibble(.iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
tour_1 <- mh_tour(start = 3, N = 5000, w = 1)

tour_1 |> 
  ggplot(aes(x = .iteration, y = mu)) +
  geom_line(size = 0.1, alpha = 0.75)
```

```{r}
tour_1 |> 
  ggplot(aes(x = mu)) +
  geom_histogram(aes(y = after_stat(density)),binwidth = 0.25, 
                  color = "white", fill = "firebrick3") +
  geom_function(fun = ~dnorm(., 4, 0.6), color = "grey12")
```

## Chapter 8: Posterior Inference and Prediction

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(tidybayes)
library(ggdist)

set_theme(theme_bw(base_family = "Barlow", base_size = 16))
```

Our prior looks like

```{r}
ggplot() +
  stat_function(fun = ~dbeta(., 4, 6), geom = "area", fill = "#f6b97b")
```

```{r}
data("moma_sample")
glimpse(moma_sample, width = 80)
```

```{r}
moma_sample |> 
  count(genx)
```

```{r}
ggplot() +
  stat_function(aes(fill = "Prior: Beta (4, 6)"), 
                fun = ~dbeta(., 4, 6), geom = "area") +
  stat_function(aes(fill = "Posterior: Beta (18, 92)"), 
                fun = ~dbeta(., 18, 92), geom = "area") +
  scale_fill_manual(values = c("#940034", "#f6b97b")) +
  theme(legend.position = "inside", legend.position.inside =  c(.8, .8))
```

```{r}
# BRMS version of approx

model_pi_brms <- brm(
  bf(num_genx | trials(artworks) ~ 0 + Intercept),
  data = list(num_genx = 14, artworks = 100),
  family = binomial(link = "identity"),
  prior(beta(4, 6), class = b, lb = 0, ub = 1),
  sample_prior = TRUE,
  iter = 5000, 
  warmup = 1000,
  seed = 1234, 
  backend = "cmdstanr", cores = 8, refresh = 0
)
```

```{r}
# stan version of approx

model_pi_stan <- cmdstan_model("08_stan/genx.stan")
```

```{r}
pi_stan_samples <- model_pi_stan$sample(
  data = list(artworks = 100, num_genx = 14),
  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500,
  refresh = 0, seed = 1234
)
```

95% credible interval:

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

95% credible interval with highest posterior densities:

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  median_hdci(pi, width = .95)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.5, 0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  labs(fill_ramp = "Credible Interval") +
  theme(legend.position = "inside", legend.position.inside = c(.83, .8))
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  count(pi < .2) |> 
  mutate(prob = n/sum(n))
```

84.73% chance that pi is less than 0.2

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot(aes(x = pi)) +
  stat_halfeye(aes(fill_ramp = after_stat(x < 0.2)), fill = "#2db25f") +
  scale_fill_ramp_discrete(from = "#8ee7af", guide = "none") +
  geom_vline(xintercept = .2, linewidth = .5, color = "grey35")
```

Region of Practical Equivalence (ROPE)

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  summarize(prop_in_rope = sum(pi > 0.25 & pi < 0.35) / n(),
            prop_outside_rope = 1 - prop_in_rope)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  annotate(geom = "rect", xmin = 0.25, xmax = 0.35, 
           ymin = -Inf, ymax = Inf, alpha = 0.3)+   geom_vline(xintercept = 0.3) +
  xlim(c(0, 0.4)) +
  theme(legend.position = "none")
```

Posterior prediction

```{r}
# brms way

predicted_genx_after_20 <- model_pi_brms |> 
  predicted_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  summarize(n = n(), .by = .prediction) |> 
  mutate(prop = n / sum(n)) |> arrange(.prediction)

predicted_genx_after_20
```

```{r}
ggplot(predicted_genx_after_20) +
  aes(x = factor(.prediction), y = prop) +
  geom_col()
```

```{r}
predicted_genx_after_20 |> 
  filter(.prediction == 3) |> 
  pull(prop)
```

Distribution of above

```{r}
model_pi_brms |> 
  epred_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  ggplot() + 
  aes(x = .epred) +
  stat_halfeye()
```

## Chapter 9: Simple Normal Regression

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(rstanarm)
library(broom.mixed)
library(tidybayes)
library(ggdist)
library(patchwork)
library(ggtext)

set_theme(theme_bw(base_family = "Barlow", base_size = 16))

data(bikes, package = "bayesrules")

bikes <- bikes |> 
  as_tibble() |> 
  mutate(temp_feel_centered = scale(temp_feel, scale = FALSE),
         temp_feel_c = as.numeric(temp_feel_centered))

temp_details <- attributes(bikes$temp_feel_centered) %>%
  set_names(janitor::make_clean_names(names(.)))
```

Our priors for our three parameters:

```{r}
p1 <- ggplot() +
  geom_function(fun = ~dnorm(., 5000, 1000), linewidth = 1, color = "#002c55") +
  xlim(c(1000, 9000)) +
  labs(x = "**β<sub>0c </sub>**<br>Average Daily<br>Ridership") +
  theme(axis.title.x = element_markdown())

p2 <- ggplot() +
  geom_function(fun = ~dnorm(., 100, 40), linewidth = 1, color = "#940034") +
  xlim(c(-50, 250)) +
  labs(x = "**β<sub>1 </sub>**<br>Temperature on<br>Ridership") +
  theme(axis.title.x = element_markdown())

p3 <- ggplot() +
  geom_function(fun = ~dexp(., 1/1250), linewidth = 1, color = "#2db25f") +
  xlim(c(0, 7000)) +
  labs(x = "**β<sub>0c </sub>**<br>Variation in<br>Ridership") +
  theme(axis.title.x = element_markdown())

p1 + p2 + p3
```

Does our prior only model produce reasonable results?

```{r}
priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma)
            )

bike_prior_only <- brm(
  bf(rides ~ temp_feel_c),
  data = bikes,
  family = gaussian(),
  prior = priors,
  sample_prior = "only",
  backend = "cmdstanr", cores = 4, seed = 1234, refresh = 0
)
```

```{r}
draws_prior <- tibble(temp_feel_c = seq(45 - temp_details$scaled_center, 90 - temp_details$scaled_center, 1)) |> 
  add_epred_draws(bike_prior_only, ndraws = 200) |> 
  mutate(unscaled = temp_feel_c + temp_details$scaled_center)

draws_prior |> 
  ggplot() +
  aes(x = unscaled, y = .epred) +
  geom_line(aes(group = .draw), alpha = .2) +
  labs(x = "Temperature", y = "Number of Rides")
```

Yes looks pretty good.

```{r}
# brms

priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma))

bike_brms <- brm(
  bf(rides ~ temp_feel_c),
  data = bikes,
  family = gaussian(),
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234, backend = "cmdstanr", refresh = 0,
  file = "09_manual_cache/bike-brms"
)
```

```{r}
bike_stan <- cmdstan_model("09_stan/bike_simple.stan")

bike_stan_samples <- bike_stan$sample(
  data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel_c),
  parallel_chains = 4, iter_warmup = 5000, iter_sampling = 5000,
  refresh = 0, seed = 1234, output_dir = "09_stan"
)
```

```{r}
neff_ratio(bike_brms)
```

```{r}
rhat(bike_brms)
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .iteration, y = .value, color = as.factor(.chain)) +
  geom_line(linewidth = 0.05) +
  labs(color = "Chain") +
  facet_wrap(~.variable, scales = "free_y") +
  theme(legend.position = "bottom")
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  group_by(.variable) |> 
  mutate(draw_rank = rank(.value)) |> 
  ggplot() +
  aes(x = draw_rank) +
  stat_bin(aes(color = factor(.chain)), geom = "step", binwidth = 1000, 
               position = position_identity(), boundary = 0) +
  labs(color = "Chain") +
  facet_wrap(~.variable) +
  theme(legend.position = "bottom", axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .value, color = factor(.chain)) +
  geom_density() +
  labs(color = "Chain") +
  facet_wrap(~.variable, scales = "free") +
  theme(legend.position = "bottom")
```

```{r}
tidy(bike_brms, conf.int = TRUE, conf.level = .8) |> 
  select(-c(effect, component, group))
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .value, fill = .variable) +
  stat_halfeye(normalize = "xy") +
  scale_fill_manual(values = c("firebrick3", "grey50", "blue4"), guide = "none") +
  facet_wrap(~.variable, scales = "free_x") +
  labs(x = "Parameter Posterior")
```

```{r}
bikes |> 
  add_linpred_draws(bike_brms, ndraws = 100) |> 
  ggplot() +
  aes(x = temp_feel, y = rides) +
  geom_point(data = bikes, size = 0.5) +
  geom_line(aes(y = .linpred, group = .draw), 
            alpha = .2, linewidth = .5, color = "navy") +
  labs(x = "Temp", y = "Rides")
```

Is beta_1 greater than 1?

```{r}
bike_brms |> 
  spread_draws(b_temp_feel_c) |> 
  count(b_temp_feel_c > 1) |> 
  mutate(prob = n / sum(n))
```

```{r}
p1 <- bike_brms |> 
  linpred_draws(newdata = tibble(temp_feel_c = (75 - temp_details$scaled_center))) |> 
  ggplot() +
  aes(x = .linpred) +
  stat_halfeye(fill = "#0188ac") +
  labs(title = "Predicted Average Riders\non all days with 75˚",
       x = "Predicted Riders", y = NULL)

p2 <- bike_brms |> 
  predicted_draws(newdata = tibble(temp_feel_c = (75 - temp_details$scaled_center))) |> 
  ggplot() +
  aes(x = .prediction) +
  stat_halfeye(fill = "#b3114b") +
  labs(title = "Predicted Riders on a\nspecific day with 75˚",
       x = "Predicted Riders", y = NULL)

p1|p2
```

```{r}
priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma))

bike_phases <- tribble(
  ~phase, ~data,
  1, slice(bikes, 1:30),
  2, slice(bikes, 1:60),
  3, bikes
) |> 
  mutate(model = map(data, ~{
    brm(
      bf(rides ~ temp_feel_c),
      data = .,
      family = gaussian(),
      prior = priors,
      chains = 4, iter = 5000*2, seed = 1234,
      backend = "cmdstanr", refresh = 0
    )
  }))
```

```{r}
bike_phases_draw <- bike_phases |> 
  mutate(draws = map(model, ~spread_draws(., b_temp_feel_c)))

phases_coefs <- bike_phases_draw |> 
  mutate(coef_plot = map2(draws, phase, ~{
    ggplot(.x) +
      aes(x = b_temp_feel_c) +
      stat_halfeye(fill = "#b3114b") +
      coord_cartesian(xlim = c(-10, 100)) +
      labs(title = paste("Phase", .y))
  }))

wrap_plots(phases_coefs$coef_plot)
```

```{r}
bike_phase_preds <- bike_phases |> 
  mutate(preds = map2(data, model, ~{
    .x |> 
      add_linpred_draws(.y, ndraws = 50) |> 
      ungroup()
  }))

phases_preds <- bike_phase_preds |> 
  mutate(pred_plot = pmap(list(data, preds, phase), ~{
    ggplot(..2, aes(x = temp_feel, y = rides)) +
      geom_point(data = ..1, size = 0.5) +
      geom_line(aes(y = .linpred, group = .draw), 
                alpha = 0.2, size = 0.5, color = "navy") +
      labs(title = paste("Phase", ..3)) +
      coord_cartesian(xlim = c(40, 90), ylim = c(0, 7000))
  }))

wrap_plots(phases_preds$pred_plot)
```

## Chapter 10: Evaluating Regression Models

```{r}
ggplot(bikes) +
  aes(x = temp_feel, y = rides) +
  geom_point(size = 1) +
  geom_smooth(method = "lm", se = FALSE, formula = "y ~ x")
```

```{r}
bike_brms |> 
  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  select(starts_with("b_"), sigma)
```

```{r}
first_draw <- bike_brms |> 
  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  slice(1)

one_rep <- bikes |> 
  mutate(mu = first_draw$b_Intercept + (first_draw$b_temp_feel_c * temp_feel_c),
         y_rep = rnorm(500, mu, first_draw$sigma))

one_rep |> 
  select(temp_feel, temp_feel_c, rides, y_rep)
```

```{r}
ggplot(one_rep) +
  aes(x = y_rep) +
  geom_density(color = "#fb7185", linewidth = 2) +
  geom_density(aes(x = rides), color = "#940034", linewidth = 2)
```

```{r}
lotsa_draws <- bike_brms |> 
  spread_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  slice_sample(n = 25) |> 
  mutate(id = 1:n())

lotsa_reps <- lotsa_draws |> 
  mutate(mu = map2(b_Intercept, b_temp_feel_c, ~.x + .y * bikes$temp_feel_c),
         y_rep = map2(mu, sigma, ~rnorm(500, .x, .y))) |>
  unnest(y_rep)

ggplot(lotsa_reps) +
  aes(x = y_rep) +
  geom_density(aes(group = id), color = "#fecdd4", linewidth = 1) +
  geom_density(data = bikes, aes(x = rides), color = "#940034", linewidth = 2)
```

```{r}
pp_check(bike_brms, ndraws = 25)
```

```{r}
bike_brms |> 
  add_predicted_draws(newdata = bikes, ndraws = 100) |> 
  ggplot() +
  aes(x = temp_feel) +
  stat_interval(aes(y = .prediction, color_ramp = after_stat(level)), alpha = .25,
                .width = c(0.5, 0.9), color = "#940034") +
  scale_color_ramp_discrete(range = c(.5, 1)) +
  geom_point(aes(y = rides), size = 2.5, pch = 21, color = "white", fill = "black")
```

```{r}
kfold_brms <- bikes |> 
  modelr::crossv_kfold(k = 10) |> 
  mutate(model = map(train, ~{
    brm(
      bf(rides ~ temp_feel_c),
      data = .,
      family = gaussian(),
      prior = priors,
      chains = 4, iter = 5000 * 2, seed = 1234, backend = "cmdstanr", refresh = 0
    )
  }))
```

```{r}
mae_kfold_brms <- kfold_brms |> 
  mutate(predictions = map2(test, model, ~{
    .x |> 
      as_tibble() |> 
      add_predicted_draws(.y) |> 
      ungroup()
  })) |> 
  mutate(mae = map(predictions, ~{
    .x |> 
      mutate(error = rides - .prediction) |> 
      summarize(
        mae = median(abs(error)),
        mae_scaled = median(abs(error / sd(.prediction)))
      )
  }))
```

```{r}
mae_kfold_brms |> 
  select(mae) |> 
  unnest(mae) |> 
  summarize(across(everything(), mean))
```

```{r}
loo(bike_brms)
```

## Chapter 11: Extending The Normal Regression Model

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(broom.mixed)
library(tidybayes)
library(ggdist)
library(patchwork)

set_theme(theme_bw(base_size = 16, base_family = "Barlow"))

data(weather_WU, package = "bayesrules")

weather_WU <- weather_WU |> 
  select(location, windspeed9am, humidity9am, pressure9am, temp9am, temp3pm) |> 
  mutate(
    across(c(temp9am, humidity9am, temp3pm, pressure9am, windspeed9am),
           ~scale(., scale = FALSE), .names = "{col}_centered")
  ) |> 
  mutate(
    across(c(temp9am, humidity9am, temp3pm, pressure9am, windspeed9am),
           ~as.numeric(scale(., scale = FALSE)), .names = "{col}_c")
  )

extract_attributes <- function(x){
  attributes(x) %>%
    set_names(janitor::make_clean_names(names(.))) %>%
    as_tibble() %>%
    slice(1)
}

unscaled <- weather_WU |> 
  select(ends_with("_centered")) |> 
  summarize(across(everything(), ~extract_attributes(.))) |> 
  pivot_longer(everything()) |> 
  unnest(value) |> 
  split(~name)
```

```{r}
ggplot(weather_WU) +
  aes(x = temp9am, y = temp3pm) +
  geom_point()
```

```{r}
priors <- c(prior(normal(25, 5), class = Intercept),
            prior(normal(0, 2.5), class = b, coef = "temp9am"),
            prior(exponential(1), class = sigma)
            )

weather_simple_brms <- brm(
  bf(temp3pm ~temp9am),
  data = weather_WU,
  family = gaussian(), 
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234, backend = "cmdstanr", refresh = 0
)
```

```{r}
pp_check(weather_simple_brms, ndraws = 25) + 
  theme(legend.position = "inside", legend.position.inside = c(.9, .8))
```

```{r}
ggplot(weather_WU) +
  aes(x = temp3pm, fill = location) +
  geom_density(color = NA) +
  paletteer::scale_fill_paletteer_d("wesanderson::GrandBudapest1") +
  labs(x = "3 PM temperature", fill = NULL) +
  theme(legend.position = "inside", legend.position.inside = c(.8, .85))
```

```{r}
ggplot(weather_WU) +
  aes(x = temp9am, y = temp3pm, color = location) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE, formula = "y ~ x") + 
  paletteer::scale_color_paletteer_d("wesanderson::GrandBudapest1") +
labs(x = "9 AM temperature", y = "3 PM temperature", color = NULL) +
  theme(legend.position = "inside", legend.position.inside = c(.15, .85))
```

Simulation of our priors

```{r}
priors <- c(
  prior(normal(25, 5), class = Intercept),
  prior(normal(0, 2.5), class = b, coef = "temp9am_c"),
  prior(normal(0, 10), class = b, coef = "locationWollongong"),
  prior(exponential(1), class = sigma)
)

weather_location_prior_brms <- brm(
  bf(temp3pm ~ temp9am_c + location),
  data = weather_WU,
  family = gaussian(), 
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234,
  backend = "cmdstanr", refresh = 0, sample_prior = "only"
)

p1 <- weather_WU |> 
  add_predicted_draws(weather_location_prior_brms, ndraws = 100) |> 
  ggplot() +
  aes(x = .prediction, group = .draw) +
  geom_density(linewidth = 0.25, color = "hotpink2")

p2 <- weather_WU |> 
  add_epred_draws(weather_location_prior_brms, ndraws = 100) |> 
  ggplot(aes(x = temp9am, y = .epred)) +
  geom_line(aes(group = paste(location, .draw), color = location), alpha = 0.2) +
  scale_color_manual(values = c("lightblue3", "firebrick3")) +
  labs(x = "9 AM temperature", y = "3 PM temperature", color = NULL) +
  theme(legend.position = "bottom")

p1 | p2
```

```{r}
priors <- c(
  prior(normal(25, 5), class = Intercept),
  prior(normal(0, 2.5), class = b, coef = "temp9am_c"),
  prior(normal(0, 10), class = b, coef = "locationWollongong"),
  prior(exponential(1), class = sigma)
)

weather_location_brms <- brm(
  bf(temp3pm ~ temp9am_c + location),
  data = weather_WU,
  family = gaussian(), 
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234,
  backend = "cmdstanr", refresh = 0
)
```

```{r}
tidy(weather_location_brms, conf.int = TRUE, conf.level = 0.8) |> 
  select(-c(component, effect, group))
```

```{r}
weather_WU |> 
  add_linpred_draws(weather_location_brms, ndraws = 100) |> 
  ggplot() +
  aes(x = temp9am, y = temp3pm, color = location) +
  geom_point(size = .5) +
  geom_line(aes(y = .linpred, group = paste(location, .draw)), 
            alpha = .2, linewidth = .5) + 
  paletteer::scale_color_paletteer_d("wesanderson::GrandBudapest1") +
  labs(x = "9 AM temperature", y = "3 PM temperature", color = NULL) +
  theme(legend.position = "inside", legend.position.inside = c(.15, .85))
```

```{r}
pp_check(weather_location_brms, ndraws = 25) +
  theme(legend.position = "inside", legend.position.inside = c(.85, .85))
```

```{r}
weather_location_brms |> 
  predicted_draws(newdata = expand_grid(temp9am_c = 10 - unscaled$temp9am_centered$scaled_center, location = c("Wollongong", "Uluru"))) |> 
  ggplot() +
  aes(x = .prediction, y = location, fill = location) +
  stat_halfeye() +
  paletteer::scale_fill_paletteer_d("wesanderson::GrandBudapest1", guide = "none") +
  labs(x = "Predicted 3 PM temperature", y = NULL)
```

```{r}
priors <- c(prior(normal(25, 5), class = Intercept),
            prior(normal(0, 2.5), class = b),
            prior(exponential(1), class = sigma))

weather_full_brms <- brm(
  bf(temp3pm ~ temp9am_c + humidity9am_c + windspeed9am_c + pressure9am_c + location),
    data = weather_WU,
  family = gaussian(),
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234, 
  backend = "cmdstanr", refresh = 0
)
```

```{r}
pp_check(weather_full_brms, ndraws = 25) +
    theme(legend.position = "inside", legend.position.inside = c(.9, .8))
```

```{r}
tidy(weather_full_brms, conf.int = TRUE, conf.level = 0.8) |> 
  select(-c(effect, component, group))
```

```{r}
models_brms <- tribble(
  ~model_name, ~model,
  "Temperature only", weather_simple_brms, 
  "Temperature + location", weather_location_brms, 
  "Full model", weather_full_brms
) |> 
  mutate(ppcheck = map2(model, model_name, ~pp_check(.x, ndraws = 25) + labs(title = .y) + theme(legend.position = "inside", legend.position.inside = c(.85, .85)))) |> 
  mutate(loo = map(model, ~loo(.)))
```

```{r}
wrap_plots(models_brms$ppcheck)
```

```{r}
loo_brms <- models_brms |> 
  mutate(loo_stuff = map(loo, ~as_tibble(.$estimates, rownames = "statistic"))) |> 
  select(model_name, loo_stuff) |> 
  unnest(loo_stuff) |> 
  filter(statistic == "elpd_loo") |> 
  arrange(desc(Estimate))

loo_brms
```

```{r}
loo_brms |> 
  mutate(model_name = fct_rev(fct_inorder(model_name))) |> 
  ggplot() +
  aes(x = Estimate, y = model_name) +
  geom_pointrange(aes(xmin = Estimate - 2* SE, xmax = Estimate + 2 * SE))
```

```{r}
models_brms |> 
  pull(loo) |> 
  set_names(models_brms$model_name) |> 
  loo_compare()
```

```{r}


cv_weather_WU <- modelr::crossv_kfold(weather_WU, k = 10) |> 
  mutate(
    model1 = map(train, ~weather_simple_brms),
    model2 = map(train, ~weather_location_brms),
    model3 = map(train, ~weather_full_brms)
  ) |> 
    mutate(predictions1 = map2(test, model1, ~{
    .x |> 
      as_tibble() |> 
      add_predicted_draws(.y) |> 
      ungroup()
  })) |> 
  mutate(predictions2 = map2(test, model2, ~{
    .x |> 
      as_tibble() |> 
      add_predicted_draws(.y) |> 
      ungroup()
  })) |> 
  mutate(predictions3 = map2(test, model3, ~{
    .x |> 
      as_tibble() |> 
      add_predicted_draws(.y) |> 
      ungroup()
  })) |> 
  mutate(mae1 = map(predictions1, ~{
    .x |> 
      mutate(error = temp3pm - .prediction) |> 
      summarize(mae = median(abs(error)),
                mae_scaled = median(abs(error / sd(.prediction))))
  })) |> 
   mutate(mae2 = map(predictions2, ~{
    .x |> 
      mutate(error = temp3pm - .prediction) |> 
      summarize(mae = median(abs(error)),
                mae_scaled = median(abs(error / sd(.prediction))))
  })) |> 
   mutate(mae3 = map(predictions3, ~{
    .x |> 
      mutate(error = temp3pm - .prediction) |> 
      summarize(mae = median(abs(error)),
                mae_scaled = median(abs(error / sd(.prediction))))
  }))
```

```{r}
res <- cv_weather_WU |> 
  select(starts_with("mae")) |> 
  unnest(starts_with("mae"), names_sep = "x") |> 
  summarize(across(everything(), mean))

res
```

```{r}
res |> 
  select(ends_with("mae")) |> 
  pivot_longer(everything()) |> 
  ggplot() +
  aes(x = value, y = name, fill = name) +
  geom_col() +
  paletteer::scale_fill_paletteer_d("wesanderson::GrandBudapest1", 
                                    guide = "none", direction = 1) +
  scale_y_discrete(labels = rev(c("Full", "Location + Temp", "Just Temp"))) +
  labs(y = NULL, x = "MAE (lower is better)") +
  scale_x_continuous(
    expand = expansion(mult = c(0.01, 0.06))
  )
```

So across our cross validation and elpd, we can see that the temperature + location is performing quite well.
