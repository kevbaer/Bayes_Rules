---
title: "Bayes_Rules!_Notebook"
format: html
editor: visual
---

## Chapter 2: Bayes' Rule

```{r}
library(bayesrules)
library(tidyverse)

set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
data(fake_news)
fake_news <- fake_news |> as_tibble()

fake_news |> 
  count(type)
```

```{r}
fake_news |> 
  summarize(n = n(), .by = c(title_has_excl, type))
```

```{r}
sim_params <- tibble(type = c("real", "fake"),
                     prior = c(0.6, 0.4))

set.seed(1234)

sims <- sample(sim_params$type, size = 10000, prob = sim_params$prior, replace = TRUE) |>
  enframe(value = "type") |> 
  mutate(data_model = case_when(
    type == "fake" ~ .2667,
    type == "real" ~ .0222
  )) |> 
  rowwise() |> 
  mutate(usage = sample(
    c("no", "yes"), size = 1, prob = c(1- data_model, data_model)
    )) |> 
  ungroup()

sims |> 
  summarize(n = n(), .by = c(usage, type))
```

```{r}
ggplot(sims) +
  aes(x = type, fill = usage) +
  geom_bar(position = "fill")
```

```{r}
data("pop_vs_soda")

pop_vs_soda |> 
  summarize(n = n(), .by = c(pop, region))
```

```{r}
chess <- c(0.2, .5, .8)
prior <- c(0.1, 0.25, 0.65)

set.seed(1234)
chess_sim <- tibble(
  pi = sample(chess, size = 10000, prob = prior, replace = TRUE) 
)|> 
  mutate(y = rbinom(n(), size = 6, prob = pi))

chess_sim |> 
  count(pi) |> 
  mutate(prop = n / sum(n))
```

```{r}
chess_sim |> 
  ggplot() +
  aes(x = y) +
  stat_count(aes(y = after_stat(prop))) +
  facet_wrap(~pi)
```

## Chapter 3: The Beta-Binomial Bayesian Model

```{r}
library(bayesrules)
library(tidyverse)
library(extraDistr)
library(brms)
library(tidybayes)
```

```{r}
ggplot() +
  geom_function(fun = ~dbeta(., 45, 55), n = 10000) +
  labs(title = "dbeta(45, 55)")
```

```{r}
model_election <- brm(
  bf(support | trials(n_in_poll) ~ 0 + Intercept),
  data = list(support = 30, n_in_poll = 50),
  family = binomial(link = "identity"),
  prior(beta(45, 55), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234, backend = "rstan",
  cores = 8
)
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
  stat_halfeye(fill = "firebrick3") +
  labs(x = "pi", title = "Posterior for Michelle's support")
```

```{r}
model_election |> 
  gather_draws(b_Intercept) |> 
  ggplot(aes(x = .value)) +
   stat_function(geom = "area", 
                fun = ~dbeta(., 45, 55), aes(fill = "Prior"), alpha = .75) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = 0.75) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  labs(x = "pi", title = "Posterior (Red) + Prior (Gray) for Michelle's support")
```

```{r}
model_milgram <- brm(
  bf(obey | trials(participants) ~ 0 + Intercept),
  data = list(obey = 26, participants = 40),
  family = binomial(link = "identity"),
  prior(beta(1, 10), class = b, lb = 0, ub = 1),
  iter = 5000, warmup = 1000, seed = 1234,
  backend = "rstan", cores = 8
)
```

```{r}
model_milgram |> 
  gather_draws(b_Intercept) |> 
  ggplot() +
  aes(x = .value) +
  geom_density(aes(fill = "Posterior"), color = NA, alpha = .75) +
  stat_function(aes(fill = "Prior"), fun = ~dbeta(., 1, 10), 
                alpha = .75, geom = "area") +
  xlim(0, 1) +
  scale_fill_manual(values = c("firebrick3", "grey37")) +
  ggtitle("Listening to Authority: Prior (Gray) vs Posterior (Red)")
```

## Chapter 6: Approximating the Posterior

```{r}
library(bayesrules)
library(tidyverse)
library(cmdstanr)
library(posterior)
library(tidybayes)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 6)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

grid_data
```

```{r}
ggplot(grid_data) +
  aes(x = pi_grid, y = posterior) +
  geom_point() +
  geom_segment(aes(xend = pi_grid, yend = 0))
```

```{r}
posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

posterior_samples|> 
  count(pi_grid)
```

```{r}
ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.1, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
grid_data <- tibble(pi_grid = seq(0, 1, length.out = 10000)) |> 
  mutate(prior = dbeta(pi_grid, 2, 2),
         likelihood = dbinom(9, 10, pi_grid)) |> 
  mutate(unnormalized = likelihood * prior,
         posterior = unnormalized / sum (unnormalized))

posterior_samples <- grid_data |> 
  slice_sample(n = 10000, replace = TRUE, weight_by = posterior) 

ggplot(posterior_samples) +
  aes(x = pi_grid) +
  geom_histogram(aes(y = after_stat(density)), 
                 color = "white", binwidth = 0.01, boundary = 0) +
  stat_function(fun = ~dbeta(., 11, 3)) +
  xlim(c(0, 1))
```

```{r}
bb_sim <- cmdstan_model("06_stan/bb_sim.stan")
```

```{r}
bb_sim_samples <- bb_sim$sample(
  data = list(Y = 9), 
  parallel_chains = 4,
  iter_warmup = 2500,
  iter_sampling = 2500,
  refresh = 0,
  seed = 1234
)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  head(4)
```

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() + 
  aes(x = pi) +
  stat_density(geom = "area", fill = "firebrick3") +
  stat_function(fun = ~dbeta(., 11, 3), color = "grey6", linewidth = 2)
```

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value, color = as.factor(.chain))) +
  geom_line(size = 0.1) +
  labs(color = "Chain")
```

Looks random!

```{r}
bb_sim_samples |>
  spread_draws(pi) |> 
  mutate(draw_rank = rank(pi)) |> 
  ggplot(aes(x = draw_rank)) +
  stat_bin(aes(color = factor(.chain)), geom = "step", binwidth = 500, 
           position = position_identity(), boundary = 0) + 
  labs(color = "Chain") +
  theme(axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())
```

According to McElreath (p. 284),

> If the chains are exploring the same space efficiently, the histograms should be similar to one another and largely overlapping.

```{r}
bb_sim_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi, color = factor(.chain)) +
  geom_density() +
  labs(color = "Chain")
```

Looks consistent across the four chains!

```{r}
brms::neff_ratio(bb_sim_samples)
```

“Our 20,000 Markov chain values are about as useful as only 6800 independent samples (0.34 × 20000).” Happy that this number is greater than .1

```{r}
bayesplot::mcmc_acf(bb_sim_samples$draws(variables = "pi"))
```

Dies off pretty quick!

```{r}
rhat_basic(bb_sim_samples$draws(variables = "pi"))
```

Not greater than 1.01 so good!

```{r}
bb_sim_samples |>
  gather_draws(pi) |> 
  ggplot(aes(x = .iteration, y = .value)) +
  geom_line(size = 0.1) 
```

Looks random enough.

## Chapter 7: Markov Chain Monte Carlo under the hood

```{r}
library(tidyverse)
set_theme(theme_bw(base_size = 16, base_family = "Barlow"))
```

"Think of Markov chains as a tour around the range of posterior possible values of a parameter (like µ or π or whatever). The chains move around that parameter and hopefully converge around it, but the chains need a tour manager to do that properly."

```{r}
one_mh_iteration <- function(w, current){
  proposal <- runif(1, min = current-w, max = current + w)
  proposal_plausibility <- dnorm(proposal, 0, 1) * dnorm(6.25, proposal, 0.75)
  current_plausibility <- dnorm(current, 0, 1) * dnorm(6.25, current, 0.75)
  
  alpha <- min(1, proposal_plausibility / current_plausibility)
  next_stop <- sample(c(proposal, current), size = 1, prob = c(alpha, 1 - alpha))
  
  return(tibble(proposal, alpha, next_stop))
}

set.seed(8)
one_mh_iteration(w = 1, current = 3)
```

```{r}
mh_tour <- function(start = 3, N, w){
  current <- start
  mu <- rep(0, N)
  
  for(i in 1:N){
    where_next <- one_mh_iteration(w = w, current = current)
    
    mu[i] <- where_next$next_stop
    
    current <- where_next$next_stop
  }
  
  return(tibble(.iteration = c(1:N), mu))
}
```

```{r}
set.seed(84735)
tour_1 <- mh_tour(start = 3, N = 5000, w = 1)

tour_1 |> 
  ggplot(aes(x = .iteration, y = mu)) +
  geom_line(size = 0.1, alpha = 0.75)
```

```{r}
tour_1 |> 
  ggplot(aes(x = mu)) +
  geom_histogram(aes(y = after_stat(density)),binwidth = 0.25, 
                  color = "white", fill = "firebrick3") +
  geom_function(fun = ~dnorm(., 4, 0.6), color = "grey12")
```

## Chapter 8: Posterior Inference and Prediction

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(tidybayes)
library(ggdist)

set_theme(theme_bw(base_family = "Barlow", base_size = 16))
```

Our prior looks like

```{r}
ggplot() +
  stat_function(fun = ~dbeta(., 4, 6), geom = "area", fill = "#f6b97b")
```

```{r}
data("moma_sample")
glimpse(moma_sample, width = 80)
```

```{r}
moma_sample |> 
  count(genx)
```

```{r}
ggplot() +
  stat_function(aes(fill = "Prior: Beta (4, 6)"), 
                fun = ~dbeta(., 4, 6), geom = "area") +
  stat_function(aes(fill = "Posterior: Beta (18, 92)"), 
                fun = ~dbeta(., 18, 92), geom = "area") +
  scale_fill_manual(values = c("#940034", "#f6b97b")) +
  theme(legend.position = "inside", legend.position.inside =  c(.8, .8))
```

```{r}
# BRMS version of approx

model_pi_brms <- brm(
  bf(num_genx | trials(artworks) ~ 0 + Intercept),
  data = list(num_genx = 14, artworks = 100),
  family = binomial(link = "identity"),
  prior(beta(4, 6), class = b, lb = 0, ub = 1),
  sample_prior = TRUE,
  iter = 5000, 
  warmup = 1000,
  seed = 1234, 
  backend = "cmdstanr", cores = 8, refresh = 0
)
```

```{r}
# stan version of approx

model_pi_stan <- cmdstan_model("08_stan/genx.stan")
```

```{r}
pi_stan_samples <- model_pi_stan$sample(
  data = list(artworks = 100, num_genx = 14),
  parallel_chains = 4, iter_warmup = 2500, iter_sampling = 2500,
  refresh = 0, seed = 1234
)
```

95% credible interval:

```{r}
qbeta(c(0.025, 0.975), 18, 92)
```

95% credible interval with highest posterior densities:

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  median_hdci(pi, width = .95)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.5, 0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  labs(fill_ramp = "Credible Interval") +
  theme(legend.position = "inside", legend.position.inside = c(.83, .8))
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  count(pi < .2) |> 
  mutate(prob = n/sum(n))
```

84.73% chance that pi is less than 0.2

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot(aes(x = pi)) +
  stat_halfeye(aes(fill_ramp = after_stat(x < 0.2)), fill = "#2db25f") +
  scale_fill_ramp_discrete(from = "#8ee7af", guide = "none") +
  geom_vline(xintercept = .2, linewidth = .5, color = "grey35")
```

Region of Practical Equivalence (ROPE)

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  summarize(prop_in_rope = sum(pi > 0.25 & pi < 0.35) / n(),
            prop_outside_rope = 1 - prop_in_rope)
```

```{r}
pi_stan_samples |> 
  spread_draws(pi) |> 
  ggplot() +
  aes(x = pi) +
  stat_slab(aes(fill_ramp = after_stat(level)),
            .width = c(0.95, 1),
            point_interval = "median_hdci",
            fill = "#d65616") +
  scale_fill_ramp_discrete(range = c(0.2, 1)) +
  annotate(geom = "rect", xmin = 0.25, xmax = 0.35, 
           ymin = -Inf, ymax = Inf, alpha = 0.3)+   geom_vline(xintercept = 0.3) +
  xlim(c(0, 0.4)) +
  theme(legend.position = "none")
```

Posterior prediction

```{r}
# brms way

predicted_genx_after_20 <- model_pi_brms |> 
  predicted_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  summarize(n = n(), .by = .prediction) |> 
  mutate(prop = n / sum(n)) |> arrange(.prediction)

predicted_genx_after_20
```

```{r}
ggplot(predicted_genx_after_20) +
  aes(x = factor(.prediction), y = prop) +
  geom_col()
```

```{r}
predicted_genx_after_20 |> 
  filter(.prediction == 3) |> 
  pull(prop)
```

Distribution of above

```{r}
model_pi_brms |> 
  epred_draws(newdata = tibble(artworks = 20)) |> 
  ungroup() |> 
  ggplot() + 
  aes(x = .epred) +
  stat_halfeye()
```

## Chapter 9: Simple Normal Regression

```{r}
library(bayesrules)
library(tidyverse)
library(brms)
library(cmdstanr)
library(rstanarm)
library(broom.mixed)
library(tidybayes)
library(ggdist)
library(patchwork)
library(ggtext)

set_theme(theme_bw(base_family = "Barlow", base_size = 16))

data(bikes, package = "bayesrules")

bikes <- bikes |> 
  as_tibble() |> 
  mutate(temp_feel_centered = scale(temp_feel, scale = FALSE),
         temp_feel_c = as.numeric(temp_feel_centered))

temp_details <- attributes(bikes$temp_feel_centered) %>%
  set_names(janitor::make_clean_names(names(.)))
```

Our priors for our three parameters:

```{r}
p1 <- ggplot() +
  geom_function(fun = ~dnorm(., 5000, 1000), linewidth = 1, color = "#002c55") +
  xlim(c(1000, 9000)) +
  labs(x = "**β<sub>0c </sub>**<br>Average Daily<br>Ridership") +
  theme(axis.title.x = element_markdown())

p2 <- ggplot() +
  geom_function(fun = ~dnorm(., 100, 40), linewidth = 1, color = "#940034") +
  xlim(c(-50, 250)) +
  labs(x = "**β<sub>1 </sub>**<br>Temperature on<br>Ridership") +
  theme(axis.title.x = element_markdown())

p3 <- ggplot() +
  geom_function(fun = ~dexp(., 1/1250), linewidth = 1, color = "#2db25f") +
  xlim(c(0, 7000)) +
  labs(x = "**β<sub>0c </sub>**<br>Variation in<br>Ridership") +
  theme(axis.title.x = element_markdown())

p1 + p2 + p3
```

Does our prior only model produce reasonable results?

```{r}
priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma)
            )

bike_prior_only <- brm(
  bf(rides ~ temp_feel_c),
  data = bikes,
  family = gaussian(),
  prior = priors,
  sample_prior = "only",
  backend = "cmdstanr", cores = 4, seed = 1234, refresh = 0
)
```

```{r}
draws_prior <- tibble(temp_feel_c = seq(45 - temp_details$scaled_center, 90 - temp_details$scaled_center, 1)) |> 
  add_epred_draws(bike_prior_only, ndraws = 200) |> 
  mutate(unscaled = temp_feel_c + temp_details$scaled_center)

draws_prior |> 
  ggplot() +
  aes(x = unscaled, y = .epred) +
  geom_line(aes(group = .draw), alpha = .2) +
  labs(x = "Temperature", y = "Number of Rides")
```

Yes looks pretty good.

```{r}
# brms

priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma))

bike_brms <- brm(
  bf(rides ~ temp_feel_c),
  data = bikes,
  family = gaussian(),
  prior = priors,
  chains = 4, iter = 5000*2, seed = 1234, backend = "cmdstanr", refresh = 0,
  file = "09_manual_cache/bike-brms"
)
```

```{r}
bike_stan <- cmdstan_model("09_stan/bike_simple.stan")

bike_stan_samples <- bike_stan$sample(
  data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel_c),
  parallel_chains = 4, iter_warmup = 5000, iter_sampling = 5000,
  refresh = 0, seed = 1234, output_dir = "09_stan"
)
```

```{r}
neff_ratio(bike_brms)
```

```{r}
rhat(bike_brms)
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .iteration, y = .value, color = as.factor(.chain)) +
  geom_line(linewidth = 0.05) +
  labs(color = "Chain") +
  facet_wrap(~.variable, scales = "free_y") +
  theme(legend.position = "bottom")
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  group_by(.variable) |> 
  mutate(draw_rank = rank(.value)) |> 
  ggplot() +
  aes(x = draw_rank) +
  stat_bin(aes(color = factor(.chain)), geom = "step", binwidth = 1000, 
               position = position_identity(), boundary = 0) +
  labs(color = "Chain") +
  facet_wrap(~.variable) +
  theme(legend.position = "bottom", axis.text.y = element_blank(), axis.title.y = element_blank(), axis.ticks.y = element_blank())
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .value, color = factor(.chain)) +
  geom_density() +
  labs(color = "Chain") +
  facet_wrap(~.variable, scales = "free") +
  theme(legend.position = "bottom")
```

```{r}
tidy(bike_brms, conf.int = TRUE, conf.level = .8) |> 
  select(-c(effect, component, group))
```

```{r}
bike_brms |> 
  gather_draws(b_Intercept, b_temp_feel_c, sigma) |> 
  ggplot() +
  aes(x = .value, fill = .variable) +
  stat_halfeye(normalize = "xy") +
  scale_fill_manual(values = c("firebrick3", "grey50", "blue4"), guide = "none") +
  facet_wrap(~.variable, scales = "free_x") +
  labs(x = "Parameter Posterior")
```

```{r}
bikes |> 
  add_linpred_draws(bike_brms, ndraws = 100) |> 
  ggplot() +
  aes(x = temp_feel, y = rides) +
  geom_point(data = bikes, size = 0.5) +
  geom_line(aes(y = .linpred, group = .draw), 
            alpha = .2, linewidth = .5, color = "navy") +
  labs(x = "Temp", y = "Rides")
```

Is beta_1 greater than 1?

```{r}
bike_brms |> 
  spread_draws(b_temp_feel_c) |> 
  count(b_temp_feel_c > 1) |> 
  mutate(prob = n / sum(n))
```

```{r}
p1 <- bike_brms |> 
  linpred_draws(newdata = tibble(temp_feel_c = (75 - temp_details$scaled_center))) |> 
  ggplot() +
  aes(x = .linpred) +
  stat_halfeye(fill = "#0188ac") +
  labs(title = "Predicted Average Riders\non all days with 75˚",
       x = "Predicted Riders", y = NULL)

p2 <- bike_brms |> 
  predicted_draws(newdata = tibble(temp_feel_c = (75 - temp_details$scaled_center))) |> 
  ggplot() +
  aes(x = .prediction) +
  stat_halfeye(fill = "#b3114b") +
  labs(title = "Predicted Riders on a\nspecific day with 75˚",
       x = "Predicted Riders", y = NULL)

p1|p2
```

```{r}
priors <- c(prior(normal(5000, 1000), class = Intercept),
            prior(normal(100, 40), class = b, coef = "temp_feel_c"),
            prior(exponential(0.0008), class = sigma))

bike_phases <- tribble(
  ~phase, ~data,
  1, slice(bikes, 1:30),
  2, slice(bikes, 1:60),
  3, bikes
) |> 
  mutate(model = map(data, ~{
    brm(
      bf(rides ~ temp_feel_c),
      data = .,
      family = gaussian(),
      prior = priors,
      chains = 4, iter = 5000*2, seed = 1234,
      backend = "cmdstanr", refresh = 0
    )
  }))
```

```{r}
bike_phases_draw <- bike_phases |> 
  mutate(draws = map(model, ~spread_draws(., b_temp_feel_c)))

phases_coefs <- bike_phases_draw |> 
  mutate(coef_plot = map2(draws, phase, ~{
    ggplot(.x) +
      aes(x = b_temp_feel_c) +
      stat_halfeye(fill = "#b3114b") +
      coord_cartesian(xlim = c(-10, 100)) +
      labs(title = paste("Phase", .y))
  }))

wrap_plots(phases_coefs$coef_plot)
```

```{r}
bike_phase_preds <- bike_phases |> 
  mutate(preds = map2(data, model, ~{
    .x |> 
      add_linpred_draws(.y, ndraws = 50) |> 
      ungroup()
  }))

phases_preds <- bike_phase_preds |> 
  mutate(pred_plot = pmap(list(data, preds, phase), ~{
    ggplot(..2, aes(x = temp_feel, y = rides)) +
      geom_point(data = ..1, size = 0.5) +
      geom_line(aes(y = .linpred, group = .draw), 
                alpha = 0.2, size = 0.5, color = "navy") +
      labs(title = paste("Phase", ..3)) +
      coord_cartesian(xlim = c(40, 90), ylim = c(0, 7000))
  }))

wrap_plots(phases_preds$pred_plot)
```
